import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import BaggingClassifier
from sklearn.model_selection import train_test_split,GridSearchCV
from sklearn.metrics import classification_report,confusion_matrix,accuracy_score,r2_score
from sklearn.datasets import load_wine
from matplotlib import style
style.use('fivethirtyeight')

wine_data=load_wine()
x=wine_data.data
y=wine_data.target


x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=7)


def bagging():
    bag_clf=BaggingClassifier(DecisionTreeClassifier(),
                              n_estimators=500,
                              bootstrap=True,
                              n_jobs=-1,
                              max_samples=50)
    bag_clf.fit(x_train,y_train)
    y_pred=bag_clf.predict(x_test)
    print(confusion_matrix(y_test,y_pred))
    print(classification_report(y_test,y_pred))
    
def random_forest():
    rnf=RandomForestClassifier()
    rnf.fit(x_train,y_train)
    y_pred=rnf.predict(x_test)
    print(confusion_matrix(y_test,y_pred))
    print(classification_report(y_test,y_pred))
    for name,score in zip(wine_data['feature_names'],rnf.feature_importances_):
        print(name , score)
    plt_x=np.array(x_test[:,9:10])
    plt_y=np.array(x_test[:,6:7])
    plt.plot([],[],color='red',label='class 0',linewidth=5)
    plt.plot([],[],color='blue',label='class 1',linewidth=5)
    plt.plot([],[],color='green',label='class 2',linewidth=5)
    for i in range(len(plt_x)):
        if y_pred[i]==0:
            plt.scatter(plt_x[i],plt_y[i],s=100,marker='*',color='red')
        elif y_pred[i]==1:
            plt.scatter(plt_x[i],plt_y[i],s=100,marker='D',color='blue')
        else:
            plt.scatter(plt_x[i],plt_y[i],s=100,marker='o',color='green')
    plt.legend(frameon=True)
    plt.show()
    
print("bagging and pasting")    
bagging()
print("RandomForestClassifier")
random_forest()


#output

runfile('H:/machine learnig/notes/supervised/ensemble methods/voting classifier on wine dataset/voting classifier algorithm.py', wdir='H:/machine learnig/notes/supervised/ensemble methods/voting classifier on wine dataset')
bagging and pasting
[[ 9  0  0]
 [ 1 18  0]
 [ 0  0 17]]
              precision    recall  f1-score   support

           0       0.90      1.00      0.95         9
           1       1.00      0.95      0.97        19
           2       1.00      1.00      1.00        17

    accuracy                           0.98        45
   macro avg       0.97      0.98      0.97        45
weighted avg       0.98      0.98      0.98        45

RandomForestClassifier
[[ 9  0  0]
 [ 0 19  0]
 [ 0  0 17]]
              precision    recall  f1-score   support

           0       1.00      1.00      1.00         9
           1       1.00      1.00      1.00        19
           2       1.00      1.00      1.00        17

    accuracy                           1.00        45
   macro avg       1.00      1.00      1.00        45
weighted avg       1.00      1.00      1.00        45

alcohol 0.04257834808932833
malic_acid 0.002611050725733705
ash 0.018981549581334894
alcalinity_of_ash 0.01620839612365036
magnesium 0.038533876222025296
total_phenols 0.090577839877527
flavanoids 0.1749949758777551
nonflavanoid_phenols 0.0
proanthocyanins 0.009109589041095892
color_intensity 0.3107121809383885
hue 0.1018857103702611
od280/od315_of_diluted_wines 0.08304250965769047
proline 0.11076397349520942