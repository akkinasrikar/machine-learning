import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import classification_report,confusion_matrix,r2_score
from sklearn.model_selection import cross_val_score
from sklearn.neighbors import KNeighborsClassifier

data=pd.read_csv('heart.csv')
x=np.array(data.iloc[:,0:12].values)
y=data['target']

x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=4)

def nb():
    nba=MultinomialNB()
    nba.fit(x,y)
    y_pred=nba.predict(x_test)
    cm=confusion_matrix(y_test,y_pred)
    cr=classification_report(y_test,y_pred)
    print(cross_val_score(nba,x,y,scoring='accuracy',cv=3).mean())
    print(cm)
    print(cr)
    
nb()

#output

runfile('F:/machine learnig/notes/supervised/regression/simple linear regression/smallex.py', wdir='F:/machine learnig/notes/supervised/regression/simple linear regression')
0.7524752475247526
[[20 13]
 [ 5 38]]
              precision    recall  f1-score   support

           0       0.80      0.61      0.69        33
           1       0.75      0.88      0.81        43

    accuracy                           0.76        76
   macro avg       0.77      0.74      0.75        76
weighted avg       0.77      0.76      0.76        76